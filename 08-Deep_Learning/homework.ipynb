{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4952a88",
   "metadata": {},
   "source": [
    "# HOMEWORK 8 Neural Network and Deep Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba8081e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.9.0+cu126)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34af730f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (0.24.0+cu126)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.0.2)\n",
      "Requirement already satisfied: torch==2.9.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (2.9.0+cu126)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.6)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2025.3.0)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.9.0->torchvision) (3.5.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch==2.9.0->torchvision) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.9.0->torchvision) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "%pip install torchvision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f9fd7e",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6940fb18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-12-02 08:04:20--  https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
      "Resolving github.com (github.com)... 140.82.113.4\n",
      "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-02T08%3A46%3A52Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-02T07%3A46%3A21Z&ske=2025-12-02T08%3A46%3A52Z&sks=b&skv=2018-11-09&sig=6Fe7ICxF7HdprOeL1K8q69WXGZNjcWgtbPyEoi4Ijks%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDY2NDQ2MCwibmJmIjoxNzY0NjYyNjYwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.GSr665-Bxwqjn3lGbgn0pO4_KAQYMPO505GU7kH2-k8&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream [following]\n",
      "--2025-12-02 08:04:20--  https://release-assets.githubusercontent.com/github-production-release-asset/405934815/e712cf72-f851-44e0-9c05-e711624af985?sp=r&sv=2018-11-09&sr=b&spr=https&se=2025-12-02T08%3A46%3A52Z&rscd=attachment%3B+filename%3Ddata.zip&rsct=application%2Foctet-stream&skoid=96c2d410-5711-43a1-aedd-ab1947aa7ab0&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skt=2025-12-02T07%3A46%3A21Z&ske=2025-12-02T08%3A46%3A52Z&sks=b&skv=2018-11-09&sig=6Fe7ICxF7HdprOeL1K8q69WXGZNjcWgtbPyEoi4Ijks%3D&jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmVsZWFzZS1hc3NldHMuZ2l0aHVidXNlcmNvbnRlbnQuY29tIiwia2V5Ijoia2V5MSIsImV4cCI6MTc2NDY2NDQ2MCwibmJmIjoxNzY0NjYyNjYwLCJwYXRoIjoicmVsZWFzZWFzc2V0cHJvZHVjdGlvbi5ibG9iLmNvcmUud2luZG93cy5uZXQifQ.GSr665-Bxwqjn3lGbgn0pO4_KAQYMPO505GU7kH2-k8&response-content-disposition=attachment%3B%20filename%3Ddata.zip&response-content-type=application%2Foctet-stream\n",
      "Resolving release-assets.githubusercontent.com (release-assets.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
      "Connecting to release-assets.githubusercontent.com (release-assets.githubusercontent.com)|185.199.110.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 102516572 (98M) [application/octet-stream]\n",
      "Saving to: ‘data.zip.2’\n",
      "\n",
      "data.zip.2          100%[===================>]  97.77M   249MB/s    in 0.4s    \n",
      "\n",
      "2025-12-02 08:04:21 (249 MB/s) - ‘data.zip.2’ saved [102516572/102516572]\n",
      "\n",
      "Archive:  data.zip\n",
      "replace data/test/curly/03312ac556a7d003f7570657f80392c34.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!wget https://github.com/SVizor42/ML_Zoomcamp/releases/download/straight-curly-data/data.zip\n",
    "!unzip data.zip\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0a4d026",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3026d49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "001df945",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98a4aed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=(3, 3), padding=0, stride=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 99 * 99, 64), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1) \n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.002, momentum=0.8)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2ad709",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Which loss function you will use?\n",
    "\n",
    "* nn.MSELoss()\n",
    "* `nn.BCEWithLogitsLoss()`\n",
    "* nn.CrossEntropyLoss()\n",
    "* nn.CosineEmbeddingLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3506c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eeefa41",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "\n",
    "What's the total number of parameters of the model? You can use `torchsummary` or count manually. \n",
    "\n",
    "* 896 \n",
    "* 11214912\n",
    "* 15896912\n",
    "* `20073473`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7b95783d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters: 20073473\n"
     ]
    }
   ],
   "source": [
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"Total parameters: {total_params}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406fb165",
   "metadata": {},
   "source": [
    "## Generators and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd8d5588",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406],\n",
    "        std=[0.229, 0.224, 0.225]\n",
    "    ) # ImageNet normalization\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83eb5c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((200, 200)), # Resize all images to a consistent size, e.g., 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b1efd6d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 images belonging to 2 classes.\n",
      "Found 201 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import torchvision.transforms as T\n",
    "batch_size = 20\n",
    "\n",
    "train_dir = \"data/train\"\n",
    "test_dir = \"data/test\"\n",
    "\n",
    "class_mode = \"categorical\"\n",
    "# Define a common target size for all images\n",
    "# For example, resize all images to 640x640\n",
    "target_size = (200, 200) \n",
    "resize_transform = T.Resize(target_size)\n",
    "\n",
    "# Create a resize transform\n",
    "train_datagen = ImageDataGenerator() # No additional preprocessing\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator() # No additional preprocessing\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode=class_mode,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7566e361",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "validation_dataset = datasets.ImageFolder(test_dir, transform = val_transforms)\n",
    "\n",
    "# Define the batch size\n",
    "batch_size = 64 # Or any other appropriate batch size\n",
    "\n",
    "# Create the DataLoader for the training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "96a8e0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# if torch.cuda.is_available():\n",
    "#     device = torch.device(\"cuda\")\n",
    "#     print(f\"CUDA is available! Using GPU: {torch.cuda.get_device_name(0)}\")\n",
    "# else:\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     print(\"CUDA is not available. Using CPU instead.\")\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# You can now use 'device' in your model and tensor operations, e.g.:\n",
    "# model.to(device)\n",
    "# data.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b9ed081e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 0.6532, Acc: 0.6262, Val Loss: 0.6207, Val Acc: 0.6716\n",
      "Epoch 2/10, Loss: 0.5471, Acc: 0.7100, Val Loss: 0.9127, Val Acc: 0.5871\n",
      "Epoch 3/10, Loss: 0.5899, Acc: 0.7025, Val Loss: 0.5991, Val Acc: 0.6617\n",
      "Epoch 4/10, Loss: 0.4520, Acc: 0.7950, Val Loss: 0.6652, Val Acc: 0.6318\n",
      "Epoch 5/10, Loss: 0.4402, Acc: 0.7913, Val Loss: 0.6098, Val Acc: 0.6517\n",
      "Epoch 6/10, Loss: 0.3723, Acc: 0.8350, Val Loss: 0.6258, Val Acc: 0.6816\n",
      "Epoch 7/10, Loss: 0.3117, Acc: 0.8775, Val Loss: 0.7521, Val Acc: 0.6368\n",
      "Epoch 8/10, Loss: 0.2915, Acc: 0.8800, Val Loss: 0.6390, Val Acc: 0.7164\n",
      "Epoch 9/10, Loss: 0.2464, Acc: 0.9200, Val Loss: 0.8028, Val Acc: 0.6617\n",
      "Epoch 10/10, Loss: 0.2825, Acc: 0.8712, Val Loss: 0.6741, Val Acc: 0.6716\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26465d0",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "What is the median of training accuracy for all the epochs for this model?\n",
    "\n",
    "* 0.05\n",
    "* 0.12\n",
    "* 0.40\n",
    "* `0.84`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "17b9846a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.float64(0.815)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(history['acc'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6e80df",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "What is the standard deviation of training loss for all the epochs for this model?\n",
    "\n",
    "* 0.007\n",
    "* 0.078\n",
    "* `0.171`\n",
    "* 1.710"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d2f01cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Standard deviation of training loss: 0.1343\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "training_losses = history['loss']\n",
    "std_dev_training_loss = np.std(training_losses)\n",
    "print(f\"Standard deviation of training loss: {std_dev_training_loss:.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988c0375",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c001bae5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(RandomHorizontalFlip(p=0.5),)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transforms.RandomRotation(50),\n",
    "transforms.RandomResizedCrop(200, scale=(0.9, 1.0), ratio=(0.9, 1.1)),\n",
    "transforms.RandomHorizontalFlip(),"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f540da30",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "\n",
    "Let's train our model for 10 more epochs using the same code as previously.\n",
    "\n",
    "> **Note:** make sure you don't re-create the model.\n",
    "> we want to continue training the model we already started training.\n",
    "\n",
    "What is the mean of test loss for all the epochs for the model trained with augmentations?\n",
    "\n",
    "* 0.008\n",
    "* 0.08\n",
    "* `0.88`\n",
    "* 8.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9c3a584e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Loss: 0.1910, Acc: 0.9487, Val Loss: 0.6531, Val Acc: 0.7164\n",
      "Epoch 2/20, Loss: 0.1665, Acc: 0.9437, Val Loss: 0.6738, Val Acc: 0.6965\n",
      "Epoch 3/20, Loss: 0.1246, Acc: 0.9775, Val Loss: 0.7079, Val Acc: 0.7114\n",
      "Epoch 4/20, Loss: 0.0942, Acc: 0.9912, Val Loss: 0.7305, Val Acc: 0.7313\n",
      "Epoch 5/20, Loss: 0.1087, Acc: 0.9750, Val Loss: 0.7523, Val Acc: 0.7015\n",
      "Epoch 6/20, Loss: 0.0677, Acc: 0.9950, Val Loss: 0.7691, Val Acc: 0.7313\n",
      "Epoch 7/20, Loss: 0.0497, Acc: 1.0000, Val Loss: 0.7516, Val Acc: 0.7214\n",
      "Epoch 8/20, Loss: 0.0472, Acc: 0.9975, Val Loss: 0.8698, Val Acc: 0.6965\n",
      "Epoch 9/20, Loss: 0.0375, Acc: 1.0000, Val Loss: 0.7999, Val Acc: 0.7313\n",
      "Epoch 10/20, Loss: 0.0409, Acc: 1.0000, Val Loss: 0.8134, Val Acc: 0.7413\n",
      "Epoch 11/20, Loss: 0.0263, Acc: 1.0000, Val Loss: 0.8756, Val Acc: 0.7413\n",
      "Epoch 12/20, Loss: 0.0210, Acc: 1.0000, Val Loss: 0.8967, Val Acc: 0.7214\n",
      "Epoch 13/20, Loss: 0.0189, Acc: 1.0000, Val Loss: 0.8697, Val Acc: 0.7413\n",
      "Epoch 14/20, Loss: 0.0160, Acc: 1.0000, Val Loss: 0.9239, Val Acc: 0.7214\n",
      "Epoch 15/20, Loss: 0.0159, Acc: 1.0000, Val Loss: 0.9185, Val Acc: 0.7363\n",
      "Epoch 16/20, Loss: 0.0136, Acc: 1.0000, Val Loss: 0.9160, Val Acc: 0.7413\n",
      "Epoch 17/20, Loss: 0.0117, Acc: 1.0000, Val Loss: 0.9510, Val Acc: 0.7363\n",
      "Epoch 18/20, Loss: 0.0106, Acc: 1.0000, Val Loss: 0.9194, Val Acc: 0.7363\n",
      "Epoch 19/20, Loss: 0.0099, Acc: 1.0000, Val Loss: 0.9526, Val Acc: 0.7413\n",
      "Epoch 20/20, Loss: 0.0090, Acc: 1.0000, Val Loss: 0.9585, Val Acc: 0.7363\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "history = {'acc': [], 'loss': [], 'val_acc': [], 'val_loss': []}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct_train = 0\n",
    "    total_train = 0\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        labels = labels.float().unsqueeze(1) # Ensure labels are float and have shape (batch_size, 1)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        # For binary classification with BCEWithLogitsLoss, apply sigmoid to outputs before thresholding for accuracy\n",
    "        predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "        total_train += labels.size(0)\n",
    "        correct_train += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_dataset)\n",
    "    epoch_acc = correct_train / total_train\n",
    "    history['loss'].append(epoch_loss)\n",
    "    history['acc'].append(epoch_acc)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in validation_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            labels = labels.float().unsqueeze(1)\n",
    "\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_running_loss += loss.item() * images.size(0)\n",
    "            predicted = (torch.sigmoid(outputs) > 0.5).float()\n",
    "            total_val += labels.size(0)\n",
    "            correct_val += (predicted == labels).sum().item()\n",
    "\n",
    "    val_epoch_loss = val_running_loss / len(validation_dataset)\n",
    "    val_epoch_acc = correct_val / total_val\n",
    "    history['val_loss'].append(val_epoch_loss)\n",
    "    history['val_acc'].append(val_epoch_acc)\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, \"\n",
    "          f\"Loss: {epoch_loss:.4f}, Acc: {epoch_acc:.4f}, \"\n",
    "          f\"Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f6ce5e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean test loss: 0.835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mean_test_loss = np.mean(history['val_loss'])\n",
    "print(f\"Mean test loss: {mean_test_loss:.3f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35ebce9c",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "What's the average of test accuracy for the last 5 epochs (from 6 to 10)\n",
    "for the model trained with augmentations?\n",
    "\n",
    "* 0.08\n",
    "* 0.28\n",
    "* `0.68`\n",
    "* 0.98"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c30dfcbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7243781094527363\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "average_test_accuracy = np.mean(history['val_acc'][5:10])\n",
    "print(average_test_accuracy)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

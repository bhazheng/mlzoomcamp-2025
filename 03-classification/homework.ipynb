{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c30695fe",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "\n",
    "* Check if the missing values are presented in the features.\n",
    "* If there are missing values:\n",
    "    * For caterogiral features, replace them with 'NA'\n",
    "    * For numerical features, replace with with 0.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ad06d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "608d3637",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>referral</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>referral</td>\n",
       "      <td>technology</td>\n",
       "      <td>3</td>\n",
       "      <td>65259.0</td>\n",
       "      <td>student</td>\n",
       "      <td>europe</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>45688.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>referral</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>71016.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>finance</td>\n",
       "      <td>3</td>\n",
       "      <td>92855.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
       "0           paid_ads            NaN                         1        79450.0   \n",
       "1       social_media         retail                         1        46992.0   \n",
       "2             events     healthcare                         5        78796.0   \n",
       "3           paid_ads         retail                         2        83843.0   \n",
       "4           referral      education                         3        85012.0   \n",
       "...              ...            ...                       ...            ...   \n",
       "1457        referral  manufacturing                         1            NaN   \n",
       "1458        referral     technology                         3        65259.0   \n",
       "1459        paid_ads     technology                         1        45688.0   \n",
       "1460        referral            NaN                         5        71016.0   \n",
       "1461  organic_search        finance                         3        92855.0   \n",
       "\n",
       "     employment_status       location  interaction_count  lead_score  \\\n",
       "0           unemployed  south_america                  4        0.94   \n",
       "1             employed  south_america                  1        0.80   \n",
       "2           unemployed      australia                  3        0.69   \n",
       "3                  NaN      australia                  1        0.87   \n",
       "4        self_employed         europe                  3        0.62   \n",
       "...                ...            ...                ...         ...   \n",
       "1457     self_employed  north_america                  4        0.53   \n",
       "1458           student         europe                  2        0.24   \n",
       "1459           student  north_america                  3        0.02   \n",
       "1460     self_employed  north_america                  0        0.25   \n",
       "1461           student  north_america                  3        0.41   \n",
       "\n",
       "      converted  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1457          1  \n",
       "1458          1  \n",
       "1459          1  \n",
       "1460          1  \n",
       "1461          1  \n",
       "\n",
       "[1462 rows x 9 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('course_lead_scoring.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb3759bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 128\n",
       "industry                    134\n",
       "number_of_courses_viewed      0\n",
       "annual_income               181\n",
       "employment_status           100\n",
       "location                     63\n",
       "interaction_count             0\n",
       "lead_score                    0\n",
       "converted                     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ce799cce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "lead_source                 0\n",
       "industry                    0\n",
       "number_of_courses_viewed    0\n",
       "annual_income               0\n",
       "employment_status           0\n",
       "location                    0\n",
       "interaction_count           0\n",
       "lead_score                  0\n",
       "converted                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean = df.copy()\n",
    "for col in df_clean.columns:\n",
    "    if df_clean[col].dtype == 'object':\n",
    "        df_clean[col] = df_clean[col].fillna('NA')\n",
    "    else:\n",
    "        df_clean[col] = df_clean[col].fillna(0.0)\n",
    "\n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97c72e3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lead_source</th>\n",
       "      <th>industry</th>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>location</th>\n",
       "      <th>interaction_count</th>\n",
       "      <th>lead_score</th>\n",
       "      <th>converted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>NA</td>\n",
       "      <td>1</td>\n",
       "      <td>79450.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.94</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>social_media</td>\n",
       "      <td>retail</td>\n",
       "      <td>1</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>employed</td>\n",
       "      <td>south_america</td>\n",
       "      <td>1</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>events</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>5</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>australia</td>\n",
       "      <td>3</td>\n",
       "      <td>0.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>retail</td>\n",
       "      <td>2</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>NA</td>\n",
       "      <td>australia</td>\n",
       "      <td>1</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>referral</td>\n",
       "      <td>education</td>\n",
       "      <td>3</td>\n",
       "      <td>85012.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>europe</td>\n",
       "      <td>3</td>\n",
       "      <td>0.62</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1457</th>\n",
       "      <td>referral</td>\n",
       "      <td>manufacturing</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>4</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1458</th>\n",
       "      <td>referral</td>\n",
       "      <td>technology</td>\n",
       "      <td>3</td>\n",
       "      <td>65259.0</td>\n",
       "      <td>student</td>\n",
       "      <td>europe</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1459</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>technology</td>\n",
       "      <td>1</td>\n",
       "      <td>45688.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.02</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1460</th>\n",
       "      <td>referral</td>\n",
       "      <td>NA</td>\n",
       "      <td>5</td>\n",
       "      <td>71016.0</td>\n",
       "      <td>self_employed</td>\n",
       "      <td>north_america</td>\n",
       "      <td>0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1461</th>\n",
       "      <td>organic_search</td>\n",
       "      <td>finance</td>\n",
       "      <td>3</td>\n",
       "      <td>92855.0</td>\n",
       "      <td>student</td>\n",
       "      <td>north_america</td>\n",
       "      <td>3</td>\n",
       "      <td>0.41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1462 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lead_source       industry  number_of_courses_viewed  annual_income  \\\n",
       "0           paid_ads             NA                         1        79450.0   \n",
       "1       social_media         retail                         1        46992.0   \n",
       "2             events     healthcare                         5        78796.0   \n",
       "3           paid_ads         retail                         2        83843.0   \n",
       "4           referral      education                         3        85012.0   \n",
       "...              ...            ...                       ...            ...   \n",
       "1457        referral  manufacturing                         1            0.0   \n",
       "1458        referral     technology                         3        65259.0   \n",
       "1459        paid_ads     technology                         1        45688.0   \n",
       "1460        referral             NA                         5        71016.0   \n",
       "1461  organic_search        finance                         3        92855.0   \n",
       "\n",
       "     employment_status       location  interaction_count  lead_score  \\\n",
       "0           unemployed  south_america                  4        0.94   \n",
       "1             employed  south_america                  1        0.80   \n",
       "2           unemployed      australia                  3        0.69   \n",
       "3                   NA      australia                  1        0.87   \n",
       "4        self_employed         europe                  3        0.62   \n",
       "...                ...            ...                ...         ...   \n",
       "1457     self_employed  north_america                  4        0.53   \n",
       "1458           student         europe                  2        0.24   \n",
       "1459           student  north_america                  3        0.02   \n",
       "1460     self_employed  north_america                  0        0.25   \n",
       "1461           student  north_america                  3        0.41   \n",
       "\n",
       "      converted  \n",
       "0             1  \n",
       "1             0  \n",
       "2             1  \n",
       "3             0  \n",
       "4             1  \n",
       "...         ...  \n",
       "1457          1  \n",
       "1458          1  \n",
       "1459          1  \n",
       "1460          1  \n",
       "1461          1  \n",
       "\n",
       "[1462 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44ca2a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lead_source</th>\n",
       "      <td>paid_ads</td>\n",
       "      <td>social_media</td>\n",
       "      <td>events</td>\n",
       "      <td>paid_ads</td>\n",
       "      <td>referral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>NA</td>\n",
       "      <td>retail</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>retail</td>\n",
       "      <td>education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number_of_courses_viewed</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>annual_income</th>\n",
       "      <td>79450.0</td>\n",
       "      <td>46992.0</td>\n",
       "      <td>78796.0</td>\n",
       "      <td>83843.0</td>\n",
       "      <td>85012.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>employment_status</th>\n",
       "      <td>unemployed</td>\n",
       "      <td>employed</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>NA</td>\n",
       "      <td>self_employed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>location</th>\n",
       "      <td>south_america</td>\n",
       "      <td>south_america</td>\n",
       "      <td>australia</td>\n",
       "      <td>australia</td>\n",
       "      <td>europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>interaction_count</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lead_score</th>\n",
       "      <td>0.94</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>converted</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      0              1           2          3  \\\n",
       "lead_source                    paid_ads   social_media      events   paid_ads   \n",
       "industry                             NA         retail  healthcare     retail   \n",
       "number_of_courses_viewed              1              1           5          2   \n",
       "annual_income                   79450.0        46992.0     78796.0    83843.0   \n",
       "employment_status            unemployed       employed  unemployed         NA   \n",
       "location                  south_america  south_america   australia  australia   \n",
       "interaction_count                     4              1           3          1   \n",
       "lead_score                         0.94            0.8        0.69       0.87   \n",
       "converted                             1              0           1          0   \n",
       "\n",
       "                                      4  \n",
       "lead_source                    referral  \n",
       "industry                      education  \n",
       "number_of_courses_viewed              3  \n",
       "annual_income                   85012.0  \n",
       "employment_status         self_employed  \n",
       "location                         europe  \n",
       "interaction_count                     3  \n",
       "lead_score                         0.62  \n",
       "converted                             1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ffa440",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "What is the most frequent observation (mode) for the column `industry`?\n",
    "\n",
    "- `retail`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7de0c8e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "retail           203\n",
       "finance          200\n",
       "other            198\n",
       "healthcare       187\n",
       "education        187\n",
       "technology       179\n",
       "manufacturing    174\n",
       "NA               134\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18998de",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "Create the [correlation matrix](https://www.google.com/search?q=correlation+matrix) for the numerical features of your dataset. \n",
    "In a correlation matrix, you compute the correlation coefficient between every pair of features.\n",
    "\n",
    "What are the two features that have the biggest correlation?\n",
    "\n",
    "- `annual_income` and `interaction_count`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f7109f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Correlation values for the specified pairs ---\n",
      "'interaction_count' and 'lead_score': 0.0099\n",
      "'number_of_courses_viewed' and 'lead_score': -0.0049\n",
      "'number_of_courses_viewed' and 'interaction_count': -0.0236\n",
      "'annual_income' and 'interaction_count': 0.0270\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"\\n--- Correlation values for the specified pairs ---\")\n",
    "corr1 = df_clean['interaction_count'].corr(df_clean['lead_score'])\n",
    "corr2 = df_clean['number_of_courses_viewed'].corr(df_clean['lead_score'])\n",
    "corr3 = df_clean['number_of_courses_viewed'].corr(df_clean['interaction_count'])\n",
    "corr4 = df_clean['annual_income'].corr(df_clean['interaction_count'])\n",
    "\n",
    "print(f\"'interaction_count' and 'lead_score': {corr1:.4f}\")\n",
    "print(f\"'number_of_courses_viewed' and 'lead_score': {corr2:.4f}\")\n",
    "print(f\"'number_of_courses_viewed' and 'interaction_count': {corr3:.4f}\")\n",
    "print(f\"'annual_income' and 'interaction_count': {corr4:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf630f1",
   "metadata": {},
   "source": [
    "### Split the data\n",
    "\n",
    "* Split your data in train/val/test sets with 60%/20%/20% distribution.\n",
    "* Use Scikit-Learn for that (the `train_test_split` function) and set the seed to `42`.\n",
    "* Make sure that the target value `y` is not in your dataframe.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5974a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 877\n",
      "Validation set size: 292\n",
      "Test set size: 293\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df_clean.drop(columns=['converted'])\n",
    "y = df_clean['converted']\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")\n",
    "print(f\"Validation set size: {len(X_val)}\")\n",
    "print(f\"Test set size: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7059bb",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "* Calculate the mutual information score between `y` and other categorical variables in the dataset. Use the training set only.\n",
    "* Round the scores to 2 decimals using `round(score, 2)`.\n",
    "\n",
    "Which of these variables has the biggest mutual information score?\n",
    "  \n",
    "- `lead_source`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c47642e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lead_source          0.03\n",
      "industry             0.02\n",
      "employment_status    0.02\n",
      "location             0.00\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "import pandas as pd\n",
    "\n",
    "categorical_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "\n",
    "X_train_cat = X_train[categorical_cols].copy()\n",
    "\n",
    "for col in X_train_cat.columns:\n",
    "    X_train_cat[col] = X_train_cat[col].astype('category').cat.codes\n",
    "\n",
    "mi_scores = mutual_info_classif(X_train_cat, y_train, discrete_features=True, random_state=42)\n",
    "\n",
    "mi_series = pd.Series(mi_scores, index=categorical_cols)\n",
    "\n",
    "print(mi_series.round(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7bde26",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "* Now let's train a logistic regression.\n",
    "* Remember that we have several categorical variables in the dataset. Include them using one-hot encoding.\n",
    "* Fit the model on the training dataset.\n",
    "    - To make sure the results are reproducible across different versions of Scikit-Learn, fit the model with these parameters:\n",
    "    - `model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)`\n",
    "* Calculate the accuracy on the validation dataset and round it to 2 decimal digits.\n",
    "\n",
    "What accuracy did you get?\n",
    "\n",
    "- 0.74\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15cddf59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "categorical_cols = ['lead_source', 'industry', 'employment_status', 'location']\n",
    "numerical_cols = ['number_of_courses_viewed', 'annual_income', 'interaction_count', 'lead_score']\n",
    "\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "train_dict = X_train[categorical_cols + numerical_cols].to_dict(orient='records')\n",
    "val_dict = X_val[categorical_cols + numerical_cols].to_dict(orient='records')\n",
    "\n",
    "X_train_encoded = dv.fit_transform(train_dict)\n",
    "\n",
    "X_val_encoded = dv.transform(val_dict)\n",
    "\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "model.fit(X_train_encoded, y_train)\n",
    "\n",
    "y_pred = model.predict(X_val_encoded)\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "\n",
    "print(f\"Validation Accuracy: {accuracy:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67e2b3",
   "metadata": {},
   "source": [
    "### Question 5 \n",
    "\n",
    "* Let's find the least useful feature using the *feature elimination* technique.\n",
    "* Train a model using the same features and parameters as in Q4 (without rounding).\n",
    "* Now exclude each feature from this set and train a model without it. Record the accuracy for each model.\n",
    "* For each feature, calculate the difference between the original accuracy and the accuracy without the feature. \n",
    "\n",
    "Which of following feature has the smallest difference?\n",
    "\n",
    "- `'industry'`\n",
    "\n",
    "> **Note**: The difference doesn't have to be positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "eb0f2723",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Model Accuracy: 0.7431506849315068\n",
      "\n",
      "Accuracy without 'lead_source': 0.7295 | Difference: 0.0137\n",
      "Accuracy without 'industry': 0.7432 | Difference: 0.0000\n",
      "Accuracy without 'employment_status': 0.7466 | Difference: -0.0034\n",
      "Accuracy without 'location': 0.7432 | Difference: 0.0000\n",
      "Accuracy without 'number_of_courses_viewed': 0.6781 | Difference: 0.0651\n",
      "Accuracy without 'annual_income': 0.8562 | Difference: -0.1130\n",
      "Accuracy without 'interaction_count': 0.6747 | Difference: 0.0685\n",
      "Accuracy without 'lead_score': 0.7432 | Difference: 0.0000\n",
      "\n",
      "Feature with the smallest difference: 'industry'\n"
     ]
    }
   ],
   "source": [
    "original_accuracy = accuracy_score(y_val, model.predict(X_val_encoded))\n",
    "print(f\"Original Model Accuracy: {original_accuracy}\\n\")\n",
    "\n",
    "features = categorical_cols + numerical_cols\n",
    "accuracy_diffs = {}\n",
    "\n",
    "for feature_to_exclude in features:\n",
    "    current_features = [f for f in features if f != feature_to_exclude]\n",
    "    \n",
    "    dv_temp = DictVectorizer(sparse=False)\n",
    "    train_dict_temp = X_train[current_features].to_dict(orient='records')\n",
    "    X_train_temp_encoded = dv_temp.fit_transform(train_dict_temp)\n",
    "    \n",
    "    val_dict_temp = X_val[current_features].to_dict(orient='records')\n",
    "    X_val_temp_encoded = dv_temp.transform(val_dict_temp)\n",
    "    \n",
    "    model_temp = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000, random_state=42)\n",
    "    model_temp.fit(X_train_temp_encoded, y_train)\n",
    "    \n",
    "    accuracy_without_feature = accuracy_score(y_val, model_temp.predict(X_val_temp_encoded))\n",
    "    \n",
    "    accuracy_diffs[feature_to_exclude] = original_accuracy - accuracy_without_feature\n",
    "    print(f\"Accuracy without '{feature_to_exclude}': {accuracy_without_feature:.4f} | Difference: {accuracy_diffs[feature_to_exclude]:.4f}\")\n",
    "\n",
    "least_useful_feature = min(accuracy_diffs, key=lambda k: abs(accuracy_diffs[k]))\n",
    "print(f\"\\nFeature with the smallest difference: '{least_useful_feature}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdccbb51",
   "metadata": {},
   "source": [
    "### Question 6\n",
    "\n",
    "* Now let's train a regularized logistic regression.\n",
    "* Let's try the following values of the parameter `C`: `[0.01, 0.1, 1, 10, 100]`.\n",
    "* Train models using all the features as in Q4.\n",
    "* Calculate the accuracy on the validation dataset and round it to 3 decimal digits.\n",
    "\n",
    "Which of these `C` leads to the best accuracy on the validation set?\n",
    "\n",
    "- 0.01\n",
    "\n",
    "\n",
    "> **Note**: If there are multiple options, select the smallest `C`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3e8e51b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.01: Validation Accuracy = 0.743\n",
      "C = 0.1: Validation Accuracy = 0.743\n",
      "C = 1: Validation Accuracy = 0.743\n",
      "C = 10: Validation Accuracy = 0.743\n",
      "C = 100: Validation Accuracy = 0.743\n",
      "\n",
      "The C value that leads to the best accuracy is: 0.01\n"
     ]
    }
   ],
   "source": [
    "c_values = [0.01, 0.1, 1, 10, 100]\n",
    "accuracies = {}\n",
    "\n",
    "for c in c_values:\n",
    "    model = LogisticRegression(solver='liblinear', C=c, max_iter=1000, random_state=42)\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    \n",
    "    y_pred = model.predict(X_val_encoded)\n",
    "    acc = accuracy_score(y_val, y_pred)\n",
    "    accuracies[c] = round(acc, 3)\n",
    "    \n",
    "    print(f\"C = {c}: Validation Accuracy = {acc:.3f}\")\n",
    "\n",
    "best_c = max(accuracies, key=accuracies.get)\n",
    "\n",
    "print(f\"\\nThe C value that leads to the best accuracy is: {best_c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-zoomcamp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
